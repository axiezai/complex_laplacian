\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{xcolor}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}
\graphicspath{{./figures/}}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{lineno}
\usepackage{adjustbox}
\usepackage{natbib}
\usepackage{bm}

\title{Emergence of Canonical Functional Networks from Complex Laplacian of Structural Connectome}


\author{
  Xihe Xie\thanks{Corresponding author} \\
  Department of Neuroscience\\
  Weill Cornell Medicine\\
  New York, NY 10028 \\
  \texttt{xix2007@med.cornell.edu} \\
  %% examples of more authors
   \And
  Chang Cai \\
  Department of Radiology and Biomedical Imaging\\
  University of California, San Francisco\\
  San Francisco, CA 94143\\
  \texttt{chang.cai@ucsf.edu} \\
   \And
  Pablo F. Damasceno \\
  Department of Radiology and Biomedical Imaging\\
  University of California, San Francisco\\
  San Francisco, CA 94143\\
  \texttt{pablo.damasceno@ucsf.edu}\\
  \And
  Srikantan Nagarajan \\
  %% Affiliation \\
  Department of Radiology and Biomedical Imaging\\
  University of California, San Francisco\\
  San Francisco, CA 94143\\
  \texttt{srikantan.nagarajan@ucsf.edu} \\
  \And
  Ashish Raj \\
  %% Affiliation \\
  Department of Radiology and Biomedical Imaging\\
  University of California, San Francisco\\
  San Francisco, CA 94143\\
  \texttt{ashish.raj@ucsf.edu} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
\maketitle

\begin{abstract}
%Human brain connectivity obtained via diffusion weighted imaging represent an approximate quantification of the brain's white-matter fiber tract network, however t
%The mechanisms that sustain functional brain activity constrained by the underlying structural network remain unknown.
The mechanism that produces functional brain networks from underlying white-matter connections is still unclear. Efforts in correlational analysis, effective connectivity, and graphical models of brain networks have all provided insight into how the brain's function is linked to its structure. Here, we make use of both the structural connectome and its corresponding fiber tract distance adjacency matrix to summarize how resting-state functional activation patterns arise from the underlying structural connections of the brain. The distance adjacency matrix introduces a delay to signals being transmitted in the network, from which we are able to extract complex eigen basis of the graph Laplacian. In this work, we show that the structural eigenmodes of the brain's complex Laplacian matrix, without any functional neural activity modeling, is sufficient in reproducing the spatial patterns of canonical functional networks in the human brain. Additionally through optimizing the parameters controlling the complex structural eigenmodes, we show that the structural eigenmodes of the complex Laplacian outperforms the real-valued Laplacian eigenmodes, and particular canonical functional networks have an occupancy preference to specific subsets of the complex structural eigenmodes. These results provide further support for structural basis of functional activity, wherein by tuning a small set of global parameters such as global coupling and wave number, the structural eigenmodes of the brain can parsimoniously support canonical functional activity patterns.
\end{abstract}

% keywords can be removed
\keywords{structural connectivity \and functional networks \and graph Laplacian \and complex Laplacian}

\section{Introduction}
% modeling at different scales for SC-FC relationships
The exploration of structure and function relationships is a fundamental scientific inquiry at all levels of biological organization, and the structure-function relationship of the brain is of immense interest in neuroscience. Attempts at mathematical formulations of neuronal activity began with describing currents traveling through a neuron's membranes and being charged via ion channels\cite{hodgkin_quantitative_1952}. Recently, the focus of computational models have expanded from small populations of neurons to macroscale brain networks, which are now available via diffusion-weighted and functional magnetic resonance imaging (dMRI and fMRI). Using computational tractography on dMRI images, detailed whole brain white-matter tracts, and their connectivity can be obtained, to yield the brain's structural connectivity (SC). Using correlated activation patterns over time in fMRI data reveals functional connectivity (FC) with high spatial resolution. Such high resolution images of the brain also allowed neuroscientists to label the brain according to anatomical or functional regions of interest (ROIs) \cite{Desikan2006, craddock_whole_2012}. Subsequently, efforts in graph-theoretic modeling have emerged as an effective computational tool to study the brain's SC-FC relationship based on the parcellated brains: ROIs became nodes and connectivity strength became edges on the graph, while dynamical systems describing neuronal activity are played out on such graphs \cite{bassett_human_2009,bullmore_complex_2009,cao_topological_2014}.

%%% paragraph on what's been done in graphical modeling
Diverse graph based methods have been employed to relate the brain's SC to FC. Particularly, perturbations and evolution of the structural and functional networks were investigated using both graph theoretical statistics \cite{Honey2009, Kuceyeski2016} \textcolor{red}{needs many more cites!} as well as network controllability \cite{gu_controllability_2015, Muldoon2016}. Structurally informed models were able to achieve moderate correlation between simulated and empirical FC \cite{Honey2009}. In parallel, dynamical causal modeling (DCM) have also emerged as a powerful tool to infer effective (directional) connectivity using neurobiological models \cite{frassle_generative_2018} \textcolor{red}{This is a highly selective citation to a random paper. If you want to make this point you have to cite many more relevant papers. This point is not specifically about DCM but more generally about NMMs, which should also be cited properly}. Due to the high-dimensionality of both neural mass (NMM) and DCM models, more recent work has suggested low-dimensional processes involving diffusion or random walks on the structural graph as a simple means of simulating FC. These simpler models were equally if not more successful in predicting empirical FC than NMMs or DCMs \cite{Abdelnour2014}.  Lastly, these simpler graph diffusion models, which naturally employ the Laplacian of SC, were generalized to yield spectral graph models whereby Laplacian eigen-spectra were sufficient to reproduce empirical FC, using only a few eigenmodes \cite{Abdelnour2018, Atasoy2016}. The Laplacian matrix representation of a network can be used to find characteristic properties of the network \cite{Stewart1999}, and its eigenmodes (or spectral basis) are the orthonormal basis that represent particular patterns on the network. Such spectral graph models are computationally attractive due to low-dimensionality and more interpret able analytical solutions.

%%% paragraph on canonical functional networks + atasoy/ de ville efforts
The SC's Laplacian eigenmodes are therefore emerging as the substrate on which functional patterns of the brain can be thought to be established via almost any reasonable process of network transmission \cite{Abdelnour2018, Atasoy2016, preti_decoupling_2019}. \textcolor{red}{I am going to forward you links to more recent and review papers on this - there are so many now and we need to properly cite them} These works mainly focused on replicating canonical functional networks (CFNs), which are stable large scale circuits made up of functionally distinct ROIs distributed across the cortex that were extracted by clustering a large fMRI dataset \cite{Yeo2011}. In \cite{Yeo2011} seven CFNs (these are spatial patterns, not to be confused for the entire network of graph of the connectome) were identified. Hence recent graph modeling work has attempted to address whether these canonical patterns can emerge by only looking at the structural connectivity information of the brain.

%the functional organization of the brain can be mapped with such high confidence, then how well can SC Laplacian eigenmodes

%%% Introducing our study
Although spectral graph models have been reasonably successful, they leave several important gaps. First, they accommodate only passive spread, hence are incapable of producing oscillating or traveling phenomena, which are critical properties of brain functional activity. Second, they do not incorporate path delays caused by finite axonal conductance speed of activity propagating through brain networks. Third, they are capable of reproducing only deterministic and steady-state features of empirical brain activity, giving a single predicted FC for a given SC. Hence these models cannot easily explain the substantial variability observed amongst individuals, as well as between different recordings of the same individual. This suggests that simplistic spectral graph models will need to be augmented with a set of richer time- or individual-varying features or parameters in order to make them more realistic. Unfortunately, this is a goal that is at variance with the key attraction of these methods - their parsimony and low-dimensionality.

In this study we propose a novel spectral graph approach that is able to produce a far richer range of functional activity and dynamics without compromising on the simplicity and parsimony of the spectral graph model. We hypothesise that the introduction of realistic path delays and axonal conductance speeds can allow graph spectra to display the kinds of pattern-richness observed in real data. Hence we utilize both the SC connectivity strength matrix as measured by white-matter fiber tract density, as well as the distance matrix as measured by the average white-matter fiber tract distance between pairs of ROIs. We show that the additional distance information allows for examining of network dynamics in the complex domain in terms of a novel complex Laplacian. This approach involves only global model parameters, which between them accommodate a rich diversity of spatiotemporal patterns that are capable of closely reproducing the diversity of spatial patterning seen across a large number of healthy subjects. Through this minimalist complex diffusion model, the characteristic patterns of signal spread described by the now-complex eigen-spectra can be tuned to exhibit activation patterns resembling human CFNs. We show that the complex approach significantly and consistently exceeds the performance of existing works relating real SC Laplacian's eigen-spectra to measured FC \cite{Atasoy2016, preti_decoupling_2019, Abdelnour2018, Honey2009}. The introduction of the complex Laplacian and accompanying complex graph diffusion may be an important contribution to the emerging literature on graph models of brain activity, and furthers our understanding of the structure-function relationship in the human brain.

We begin with a general theory of complex graph diffusion incorporating path delays, leading to the emergence of the complex Laplacian. Then we present detailed statistical analysis showing the ability of complex eigenmodes to be tuned by model parameters and reproducing CFNs. We present comparison with the current approach of using real eigenmodes, followed by a detailed Discussion.

%% end of intro

\section{Methods}

\label{sec:methods}

\paragraph{Notation.} In our notation, vectors and matrices are represented in \textbf{bold}, and scalars by normal font. We denote frequency of a signal, in Hertz (Hz), by symbol $f$, and the corresponding angular frequency as $\omega = 2 \pi f$. The structural connectivity matrix is denoted by $\bm{C} = c_{jk}$, consisting of connection strength $c_{jk}$ between any two pairs of brain regions $j,k$.


\subsection{Complex Graph Laplacian Eigenmodes}

For an undirected, weighted graph representation of the structural network $c_{i,j}$, we model the average neuronal activation signal for the $i$-th region as $x_{i}(t)$:

\begin{equation} \label{eq1}
\frac{dx_{i}(t)}{dt} = -\beta (x_{i}(t) - \frac{\alpha}{\sqrt{deg_i}\sqrt{deg_j}} \sum_{i,j} c_{i,j} x_{j}(t-\tau^{\nu}_{i,j})) + p(t)
\end{equation}

Where the first term is an exponential decay describing the refractory period after neuronal discharge with a rate constant $\beta$. The second term is the input signal from the $j$-th regions connected to region $i$ scaled by the connection strength from $c_{i,j}$, normalized by row and column degree, and delayed by $t-\tau^{\nu}_{i,j}$. The term $\tau^{\nu}_{i,j}$ is the delay in seconds obtained from the distance adjacency matrix defined by $\tau^{\nu}_{i,j,} = \frac{D_{i,j}}{\nu}$. The parameter $\alpha$ acts as both a global coupling parameter as well as a diffusion rate constant to distinguish the diffusion dynamics from $\beta$. The delays between connected brain regions turn into phase shifts in the frequency profiles of the oscillating signals, thus we obtain the following Fourier transforms from (\ref{eq1}): $\frac{dx_{i}(t)}{dt} \to j\omega x_{i}(\omega)$, $x(t-\tau^{\nu}_{i,j}) \to e^{-j\omega \tau^{\nu}_{i,j}} x_{i}(\omega)$, and the oscillatory frequency $\omega = 2 \pi f$. Lastly, we combine the degree normalization term $\sqrt{deg_i}\sqrt{deg_j}$ as $\Delta$ and define a complex connectivity term $C^{*}(\omega) = \Delta^{-1} \sum_{i,j} c_{i,j}e^{-j\omega \tau^{\nu}_{i,j}}$ to obtain a closed-form solution for $\pmb{\bar{X}}(\omega)$:

% have closed form solution wih X(\omega) on one side
\begin{equation}
\label{eq2}
\pmb{\bar{X}}(\omega) = (j\omega + \beta \mathcal{L}(\alpha, k))^{-1} \pmb{P}(\omega)
\end{equation}

In this closed-form solution, we define a complex Laplacian matrix $\mathcal{L}$ as a function of global coupling $\alpha$ and wave number $k$, where $k = \frac{\omega}{\nu}$. The wave number represents the spatial frequency of any propagating wave, describing the amount of oscillations per unit distance traveled \cite{French1971}. Then the complex Laplacian matrix $\mathcal{L}$ has the form:

\begin{equation}
    \label{eq3}
    \mathcal{L}(\alpha, k) = \pmb{I} - \alpha \pmb{C}^{*}(\omega)
\end{equation}

Where $\pmb{I}$ is the identity matrix and $\pmb{C}^{*}(\omega)$ is the complex connectivity matrix as defined above. While (\ref{eq2}) indicates that the propagating signals in the network is governed by $\mathcal{L}$, the complex Laplacian of the network describes the characteristic patterns of signal spread in a network, and we can obtain these spatial patterns via the decomposition:
%we obtained the expression $\mathcal{L} = \pmb{I} - \alpha \pmb{C}^{*}(\omega)$ for a complex Laplacian matrix $\mathcal{L}(\alpha, k)$, with $\pmb{I}$ being the identity matrix. Specifically, we've inserted the variable $\tau^{\nu}_{i,j}$ to be a part of the term $\pmb{C}^{*}(\omega)$ to avoid unidentifiable parameters as  $\omega$ and $\tau_{i,j}^{\nu}$ are quotients in the same term. The ratio between a wave's oscillatory frequency and its distance traveled is defined as the wave number $k$, representing the spatial frequency of any propagating wave\cite{French1971}. Finally, This closed-form solution indicates that diffusion patterns of signals on the network is governed by the complex Laplacian matrix $\mathcal{L}$, subsequently, the characteristic diffusion patterns can be obtained via the following decomposition:

\begin{equation}
\label{eq4}
\bm{\mathcal{L}}(\alpha, k) = \sum_{n = 1}^{N} \bm{u}_{n}(\alpha, k)\bm{\lambda}_{n}(\alpha, k)\bm{u}(\alpha, k)_{n}^{H}
\end{equation}

Where $\bm{\lambda}_{n}(\alpha, k)$ are the eigenvalues of the complex Laplacian matrix and $\bm{u}_{n}(\alpha, k)$'s are the complex eigenmodes of the complex Laplacian matrix. Here, the entries of the complex eigenmodes represent the relative amount of activation in each parcellated brain region as controlled by global coupling and wave number parameters.

\subsection{Structural Connectivity Network Computation} We constructed structural connectivity networks according to the Desikan-Killiany atlas where the brain images were parcellated into 68 cortical regions and 18 subcortical regions as available in the FreeSurfer software \cite{Fischl2002, Desikan2006}. We first obtained openly available diffusion MRI data from the MGH-USC Human Connectome Project to create an average template connectome \cite{McNab2013}. Additionally, we obtained individual structural connectivity networks from 36 subjects' diffusion MRI data. Specifically, \textit{Bedpostx} was used to determine the orientation of brain fibers in conjunction with \textit{FLIRT}, as implemented in the \textit{FSL} software \cite{Jenkinson2012}. Tractography was performed using \textit{probtrackx2} to determine the elements of the adjacency matrix. We initiated 4000 streamlines from each seed voxel corresponding to a cortical or subcortical gray matter structure and tracked how many of these streamlines reached a target gray matter structure.
The weighted connection between the two structures $c_{i,j}$ was defined as the number of streamlines initiated by voxels in regions $i$ that reach any voxel within region $j$, normalized by the sum of the source and target region volumes ($c_{i,j} = \frac{streamlines}{v_i + v_j}$). This normalization prevents large brain regions from having extremely high connectivity due to having initiated or received many streamline seeds. Afterwards, connection strengths are averaged between both directions ($c_{i,j}$ and $c_{j,i}$) to form undirected edges. Additionally, to determine the geographic location of an edge, the top 95\% of non-zero voxels by streamline count were computed for both edge directions, The consensus edge was defined as the union between both post-threshold sets.

\subsection{Canonical Functional Networks}
We chose the 7 CFN parcellations mapped by Yeo et al. \cite{Yeo2011} as the functional spatial patterns most frequently visited by the human brain. The brain parcellations were created from fMRI recordings of 1000 young, healthy English speaking adults at rest with eyes open. A clustering algorithm was used to parcellate and identify consistently coupled voxels within the brain volume. The results revealed a coarse parcellation of seven networks: limbic, default, visual, frontoparietal, somatomotor, ventral attention, and dorsal attention.

The CFN parcellation was co-registered to brain regions of interest in the gyral based Desikan-Killany atlas \cite{Desikan2006} to match the dimensionality of our complex Laplacian structural eigenmodes. Then spatial activation maps of each canonical network was produced by normalizing the number of voxels per brain region belonging to a specific CFN by the total number of voxels in the brain region of interest (Fig 1). Both the functional networks and the Desikan-Killiany atlas are openly available for download from Freesurfer \cite{Fischl2012} (http://surfer.nmr.mgh.harvard.edu/).

\subsection{Global Parameter Optimization}
We performed the "basin-hopping" global optimization technique \cite{Wales1997} to find a set of parameters that provided the highest spatial correlation value between each of the CFN and the best performing complex Laplacian eigenmode. To ensure we achieve the global optimal in the nonlinear eigen decomposition process, we initiated the optimization procedure from ten different initial parameter values and selected the optimized parameters resulting from the optimization run that achieved the highest spatial correlation value. While the basin-hopping algorithm always accepts new parameters that map cost function evaluations that improves upon the previous iteration, it will also accept solutions that does not improve upon the previous iteration to move out of local minima. The acceptance probability of this new iteration is $\exp(\frac{-(f(x)_{new} - f(x)_{old})}{T})$, where $f(x)_{new}$ and $f(x)_{old}$ are the current and previous cost function evaluations respectively. $T$ is the "temperature" parameter used in the acceptance/rejection criterion, larger $T$ values indicate that the algorithm is more willing to accept larger jumps in the cost function evaluation. We use a $T$ value of $0.01$ in our optimization schemes as that is a close estimate of the difference between our local minima.

\subsection{Similarity Analysis Between Canonical Functional Networks and Structural Eigenmodes}
%Firstly, we performed the "basin-hopping" global optimization technique \cite{Wales1997} to find a set of parameters that provided the highest spatial correlation value between each of the canonical functional network and the best performing complex Laplacian eigenmode. To ensure we achieve the global optimal in the nonlinear eigen decomposition process, we initiated the optimization procedure from ten different initial parameter values and selected the optimized parameters resulting from the optimization run that achieved the highest correlation value. While the basin-hopping algorithm always accepts new parameters that map cost function evaluations that improves upon the previous iteration, it will also accept solutions that does not improve upon the previous iteration to move out of local minima. The acceptance probability of this new iteration is $\exp(\frac{-(f(x)_{new} - f(x)_{old})}{T})$, where $f(x)_{new}$ and $f(x)_{old}$ are the current and previous cost function evaluations respectively. $T$ is the "temperature" parameter used in the acceptance/rejection criterion, larger $T$ values indicate that the algorithm is more willing to accept larger jumps in the cost function evaluation. We use a $T$ value of $0.01$ in our optimization schemes as that is a close estimate of the difference between our local minima.

First, with the HCP template connectivity matrix and it's corresponding distance adjacency matrix, we obtained a single complex structural eigenmode with the highest spatial similarity for each of the seven CFNs. Additionally, the structural eigenmodes act as the basis activation patterns for a brain network, and we wanted to determine if a cumulative combination of these structural eigenmodes will improve the spatial similarity between a CFN and its structural basis patterns. Therefore, we ranked all the structural eigenmodes from the most similar to least similar to each CFN's spatial patterns using the same optimized parameters, and computed the weights that best fits the simple equation:

% % maybe we don't need this. or replace A/B/X with U_i/??coefficient??/V_n
\begin{equation}
    \mathbf{\Psi}_{CFN} = \sum_{n = 1}^{N} \mathbf{u}_{n}(\alpha,k) \theta_{n}
\end{equation}

The weights $\theta_n$ is obtained by minimizing the 2-norm of $\norm{\mathbf{\Psi}_{CFN}-\sum_{n=1}^{N} \mathbf{u}_{n}(\alpha,k) \theta_{n}}$, where $\mathbf{u}$ are the structural eigenmodes and $\mathbf{\Psi_{CFN}}$ is the vector representing spatial activation patterns of a particular CFN. Spatial similarity was computed for all possible combination of eigenmodes. While Spearman's correlation was appropriate for non-continuous correlative comparisons, it's non-linearity due to sorting of values was evident in volatile changes of spatial similarity, and Pearson's correlation provided much steadier results. Therefore, Spearman's correlation was used and reported for optimizing the best performing eigenmode, and both Spearman's and Pearson's were reported for cumulative comparisons.
% we cna also point out Yeo et al used Pearson's correlation of voxel-wise activation time series from fMRI as minimization metric in his study as well.

We repeated this analysis for both the conventional real-valued Laplacian without frequency and transmission speed tuning, as well as complex Laplacians obtained from 1000 null connectivity matrices. The null connectivity matrices were constructed with the same sparsity as the HCP template connectivity matrix, and the elements of the matrix are assigned by randomly sampling from a white-matter fiber tract distance based distribution calculated by $\exp{-\mathbf{distances}}$. The 1000 randomly sampled null connectivity matrices allow us to generate a null distribution of spatial correlation values and compare the performance of a brain graph's complex and real-valued Laplacian eigenmodes to the null distribution.

\section{Result}

\subsection{Structural connectivity based functional activation patterns}
First, we use the HCP template connectome to demonstrate the wide range of spatial activity patterns achievable by the eigenmodes of the complex Laplacian matrix. The top row of Figure 2 shows three exemplary structural eigenmodes (absolute values, since modes are complex) with high coupling strength ($\alpha = 2.5$) and high propagation speed ($k = 2$). Each eigenmode shows distinct spatial activation patterns: eigenmode 1 has high activity in the lateral temporal brain regions, whereas the medial brain regions of eigenmode 2 has the higher activations, and eigenmode 3 engages inferior brain regions along both the midline and lateral periphery of the brain. Middle row shows exemplary structural eigenmodes at a different parameter tuning: low coupling strength ($\alpha = 0.2$), and low speed ($k = 8$). Now eigenmodes 1 and 3 show a rather different spatial pattern, with left and right hemisphere specific activation around the dorsal brain regions while eigenmode 2 recruits both the frontal and occipital regions in both hemispheres. Consistent with previous works of structural network eigenmodes \cite{Atasoy2016, Abdelnour2018}, we show in the last row that a real valued Laplacian without frequency and transmission speed tuning is capable of producing similar spatial patterns. The coupling strength parameter $\alpha$ is the only parameter in this case, and we find this overall scaling has very minuscule effect on the spatial patterns of individual eigenmodes. These results exemplify the concept that while complex eigenmodes are capable of producing the kinds of spatial patterns produced by real eigenmodes, they can accommodate a much richer diversity of patterns that are tunable by the two key biophysically meaningful parameters: propagation speed and coupling strength.

\subsection{Eigenmodes of the complex Laplacian resemble CFN activation patterns}
We re-assigned the voxel-wise parcellations of the seven CFNs from Yeo et al. \cite{Yeo2011} to brain regions from the Desikan-Killiany atlas (Figure 3, left column), this re-sampling of the parcellations allow spatial pattern comparisons of equal dimensions against our eigenmodes. The middle column of Figure 3 shows best matching eigenmodes after global optimization of the complex Laplacian calculated from the HCP template connectome, to each CFN. In addition to displaying the best-performing eigenmode in each case, we further ranked the eigenmodes according to their spatial correlation values and displayed the linear combination of the top 10 performing eigenmodes on the right column of Figure 3. The spatial correlation values of the best performing eigenmode, and details of cumulative combinations of eigenmodes are reported below and in Figure 5.

We observe that CFN patterns emerge when parameters, optimized for each network, are applied to the complex Laplacian. Only a few eigenmodes are sufficient to capture each CFN. \textcolor{red}{Suggest remove this, probably confusing} While we only tune the parameters for a single best performing structural eigenmode, which is shown in the middle column of Figure 3, combining additional eigenmodes from the same parameter set improves spatial similarity despite those subsequent eigenmodes being untuned to a particular CFN.

% Possible discussion point %
% and After ranking the structural eigenmodes by their spatial similarities to canonical functional networks, we find that the best performing eigenmodes act as dominant structural basis for each canonical functional network. Furthermore, combinations of additional high ranking eigenmodes improve spatial similarity.

\subsection{Parameter tuning of complex Laplacian eigenmodes}
To examine the sensitivity of our eigenmodes to our complex Laplacian parameters, we first computed spatial correlation values for the all eigenmodes for each CFN across the entire parameter range. Figure 4 (top) shows the effect of fixing $k$ and varying $\alpha$, while bottom row shows the effect of varying $k$ at a fixed $\alpha$. Several pertinent observations are enumerated below:
\begin{enumerate}
    \item It is evident that we need to tune both the global coupling strength and wave number for a dominant eigenmode matching a specific CFN to emerge.
    \item Almost all eigenmodes are capable of resembling any given CFN, with the proper choice of tuning parameters.
    \item Certain parameter regimes recruit multiple eigenmodes while others recruit a single one, for any given CFN. This is especially true of the wavenumber parameter and not so for correlation strength parameter.
    \item The best achievable spatial correlation for all networks stay consistent as we change the global coupling strength parameter, whereas wave number tuning causes shifts in spatial similarity between the best performing eigenmode and CFNs as well as which particular eigenmode achieves the highest spatial correlation.
    \item The limbic network has the worst spatial match and the least amount of shift in spatial correlation values.

\end{enumerate}

To further examine the tunable parameter's effects on the dominant eigenmode, we show a heat map of the spatial correlation achieved by the dominant eigenmode as we shifted parameter values in Supplementary Figure 1. As expected, global coupling parameter had no effect on dominant eigenmode's fit while the wave number did. Subsequently, we split the wave number parameter into its two components: signal transmission velocity and oscillatory frequency, showing that those two components equally affect spatial patterns emerging from the complex Laplacian eigenmodes (Supp. Figure 1 bottom row). The spatial correlation patterns of each functional network also implies that there are potentially functional network specific eigenmodes obtainable from the structural complex Laplacian, which will be explored further in the subsequent group level analysis.

\subsection{Complex Laplacian eigenmodes outperform real Laplacian eigenmodes}
To compare the performance of the complex Laplacian structural eigenmodes, we performed the same similarity analysis with the HCP connectome's real-valued Laplacian eigenmodes as well as complex Laplacian eigenmodes of randomly sampled networks. We specifically created 1000 random networks and for each combination of eigenmodes, we calculated a 95\% confidence interval from the Fisher's r to z values and obtained Bonferroni-corrected one-tail p-values for all null distribution comparisons.

Overall, the complex Laplacian's best-performing eigenmodes outperform real-valued Laplacian eigenmodes in 6 out of the 7 CFNs as shown in Figure 5 (left-most point on each curve). In comparison to the null distribution of randomly generated Laplacian eigenmodes, the complex Laplacian's top performing eigenmode significantly outperforms the random eigenmodes in all cases. The ventral attention network comparison has the highest p-value of $p=0.0044$, while all other comparisons achieved $p< 0.0001$. On the other hand, the real-valued regular Laplacian's top performing eigenmode significantly outperformed the random Laplacian eigenmodes when comparing the limbic, default mode, and visual networks only ($p<0.001$).

\textbf{ Cumulative eigenmodes}. We then repeated the above analysis, this time taking the top $k, k\in [1,30]$ eigenmodes. For each cumulative set we fitted a linear regression (see Methods) to obtain the best weighted sum of the eigenmodes that best describes the CFN. Note that $k=10$ corresponds to the visual results in Figure 3, for which the complex Laplacian achieved $p<0.0001$ for all CFN comparisons, while the regular Laplacian yielded $p<0.0005$ for all networks except the ventral attention network ($p<0.01$). The curves of Figure 5 go up to $k=30$; the cumulative combination of eigenmodes show an overall upward trend of spatial Pearson's correlation. The Spearman's correlation values are less stable in comparison, due to the non-linear sorting operations, but also show overall increases with $k$. Beyond 30, combining more eigenmodes continue to steadily improve correlation with CFNs, until the complete basis of 86 eigenmodes is reached (not shown). This is because the full set of eigenmodes constitutes an orthonormal basis capable of spanning any function on the graph. Therefore the presented results are only biologically interpretable for small $k$ - the reason we sweep it only to 30.

%% add in discussion? - In other words, is a functioning brain able to recruit and tune neuronal activity as organized by basis structural patterns to access functional networks.
\subsection{Group level eigenmode analysis}
Figure 6 shows a violin plot of the best spatial correlation achieved by each subject's complex Laplacian in orange and real Laplacian in blue. Paired T-tests were performed for all CFNs. The complex Laplacian eigenmodes outperform real ones at the group level for all networks except the limbic network. The paired T-tests between the two Laplacian types for all remaining networks had Bonferroni corrected p-values below $p = 0.01$.

Lastly, with the exception of the default mode network, whose best performing structural eigenmodes span across the range of all eigenmodes numbers, all other CFNs exhibit selectivity towards a specific subset of eigenmodes (Figure 7). The limbic and visual networks prefer to occupy structural eigenmodes at both low and high ends of the eigen-spectrum, while the dorsal and ventral attention networks mainly occupy the middle of the eigen-spectrum. The specific occupancy patterns shown in Figure 8 implies there may be a hierarchy to the CFNs that are accessible by the underlying structural connections of the brain, and the functioning brain minimizes recruitment of unrelated structural connections when engaged in specific tasks.

\section{Discussion}

Recent graph models involving eigenspectra of the adjacency or Laplacian matrices of the structural connectome have greatly contributed to our understanding of how the brain's structural wiring gives rise to its functional patterns of activity. These models have very attractive features of parsimony and low-dimensionality, but suffer from the basic issue of static predictions and are feature-poor. In this study we have proposed a complex graph Laplacian that sustains a far greater richness of patterns, while at the same time keeping the attractive properties of parsimony and low-dimensionality. The model involves only two global and biophysically meaningful parameters, controlling the speed of activity propagation, and the coupling strength between remote populations of neurons connected via axonal projections. We presented detailed statistical analysis of the complex Laplacian eigenmodes, focusing on their ability to predict the spatial patterns observed on seven CFNs that are well established in functional neuroimaging. Our main contributions are summarized below, with additional context and implications from current literature.

\subsection{A simple yet feature-rich graph theoretic approach }
We first derived a simple model of network diffusion of activity which takes into account the path delays introduced by realistic axonal conductance speeds and fiber lengths, and showed that at the first order the behavior of the model can be captured within a complex Laplacian, on which a complex-valued graph diffusion process is enacted. Using this definition of the complex Laplacian we demonstrated that its eigenmodes constitute a sparse basis that is capable of reproducing the characteristic spatial patterns of empirical resting state functional activity given by the 7 CFNs.

\subsection{Higher predictive power than existing graph models}
We showed that the Complex Laplacian outperforms the existing models that use the eigenmodes of real-valued Laplacian. These results are far better than can be expected by chance, as indicated by the significance values of our results with respect to large simulations with Laplacians calculated from random connectomes. Thus, future graph models can benefit from the enhanced predictive power of the proposed complex Laplacian approach, which in the cases we have tested highly significantly improves performance, measured via Pearson's correlation strength ($p<0.001$, see Figure 6). Our work can therefore find direct applicability in many clinical and neuroscientific contexts where predicting functional patterns from structure is important, see e.g. some recent application papers \textcolor{red}{(CITE ??)}.

\subsection{Complex eigenmodes accommodate a diversity of spatial patterns}
One of the most intriguing aspects of our study is the demonstration that almost all (complex) eigenmodes are capable of resembling any given CFN, with the proper choice of tuning parameters. As observed from Figure 4, certain parameter regimes recruit multiple eigenmodes while others recruit a single one; however with the right selection of the two model parameters, it is possible to "steer" the eigenmodes in such a manner that a small number of them can reproduce any CFN. This not only denotes the strength of our approach, we believe it points to an essential characteristic of real brain activity, which is thought to accommodate a large repertoire of microstates and their concomitant spatial patterns. This rich repertoire was shown above to be capable of being engaged by our parsimonious graph model, which may point to the possibility that complex behavior may be achievable by simple and parsimonious mechanisms, and may not require the kinds of high-dimensional and non-linear oscillatory models that have held sway in the field of neural modeling \textcolor{red}{(CITE SOME NMM PAPERS)}.

\subsection{Rich repertoire is tunable by only two biophysical parameters}
In our model, the brain can access any configuration of spatial patterns seen in real resting state functional networks by tuning only two of its global and biophysically meaningful parameters: coupling strength and wave number. This demonstration in an analytical model, that a rich repertoire of states is accessible to the brain by tuning biophysical processes, has not previously been reported to our knowledge.

It is not possible in a simple computational study like ours to explore the neural mechanisms that might control the above model parameters, or how such control can be enacted in real time. We may speculate however that modern neuroscience provides several potential mechanisms. It is not clear whether axonal conductance speed is dynamic, but the dependence on speed is not necessary to exert control over the wavenumber parameter we propose - this can be achieved via the frequency of oscillation $\omega$. From the deep literature on wideband frequency response of brain recordings, it is already known that different functional networks of resting state BOLD data are preferentially encapsulated by different higher-frequency bands via phase- and amplitude-coupling \textcolor{red}{(CITE SOME PAPERS)}. Hence it is likely that our wavenumber-tuning may simply reflect a frequency band-specific behavior. This does not preclude the possibility that in fact conductance speed can also be modulated in real time. The second parameter, coupling strength, is possibly more straightforward to implement in the biological substrates of the brain, e.g. via calcium and potassium channels, adaptive synaptic strength or time-dependent plasticity, etc, to name only a few possibilities.

 3) There is a possible organizational hierarchy, cite neurosynth etc as examples of this theory.
 4) Discuss amongst the 7 networks, which ones were captured the best, and possibly why.
 5) These are cortical functional networks, how important is the brainstem in brain function? How to justify these networks leaving out the brainstem?

 - discuss limitations
 1) simulations with connectomes only partially replicated resting state networks because ... Reasons for this limitation
 2) are the resulting correlations between simulated and empirical FC reasonable? Compared to those using more complicated and parameterized models?
 3) What are some possible ways to improve our methodology?

 - In conclusion ...



\bibliographystyle{unsrt}
\bibliography{references.bib}

\end{document}
