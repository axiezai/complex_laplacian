{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Laplacian & Random/Null Laplacian Comparison\n",
    "--\n",
    "\n",
    "Here we compare the complex Laplacian performance:\n",
    " 1) The regular Laplacian does not have the wave number $k$ parameter, and does not have a complex component. \n",
    " 2) Random Laplacian uses values sampled from a distribution of pairwise Brain ROI distances, the sampled connectome is symmetrized, with 0 diagonal, and have similar sparsity as the actual HCP template connectome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.linalg import lstsq\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# spectrome imports:\n",
    "from spectrome.brain import Brain\n",
    "from spectrome.utils import functions, path, generate\n",
    "from spectrome.forward import eigenmode, laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normal house-keeping:\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# Load Pablo's Yeo 2017 canonical network maps\n",
    "#fc_dk = np.load(\"../data/com_dk.npy\", allow_pickle=True).item()\n",
    "fc_dk_normalized = pd.read_csv(\"../data/DK_dictionary_normalized.csv\").set_index(\n",
    "    \"Unnamed: 0\"\n",
    ")\n",
    "\n",
    "# define list of canonical network names and re-order the dictionary using these names:\n",
    "fc_names = [\n",
    "    \"Limbic\",\n",
    "    \"Default\",\n",
    "    \"Visual\",\n",
    "    \"Fronto \\n parietal\",\n",
    "    \"Somato \\n motor\",\n",
    "    \"Dorsal \\n Attention\",\n",
    "    \"Ventral \\n Attention\",\n",
    "]\n",
    "\n",
    "fc_dk_normalized = fc_dk_normalized.reindex(\n",
    "    [\n",
    "        \"Limbic\",\n",
    "        \"Default\",\n",
    "        \"Visual\",\n",
    "        \"Frontoparietal\",\n",
    "        \"Somatomotor\",\n",
    "        \"Dorsal_Attention\",\n",
    "        \"Ventral_Attention\",\n",
    "    ]\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load optimal results from complex Laplacian optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_param = np.zeros([len(fc_names), 2])\n",
    "\n",
    "## Load the optimized parameters first\n",
    "h5_path = os.path.join(data_dir, \"default.h5\")\n",
    "bh_default = path.read_hdf5(h5_path)\n",
    "opt_param[1, :] = bh_default[\"x\"]\n",
    "# print('Default network parameters:' + str(np.round(bh_default['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"dorsal.h5\")\n",
    "bh_dorsal = path.read_hdf5(h5_path)\n",
    "opt_param[5, :] = bh_dorsal[\"x\"]\n",
    "# print('Doral Attention network parameters:' + str(np.round(bh_dorsal['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"fronto.h5\")\n",
    "bh_front = path.read_hdf5(h5_path)\n",
    "opt_param[3, :] = bh_front[\"x\"]\n",
    "# print('Frontoparietal network parameters:' + str(np.round(bh_front['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"limbic.h5\")\n",
    "bh_limbic = path.read_hdf5(h5_path)\n",
    "opt_param[0, :] = bh_limbic[\"x\"]\n",
    "# print('Limbic network parameters:' + str(np.round(bh_limbic['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"motor.h5\")\n",
    "bh_motor = path.read_hdf5(h5_path)\n",
    "opt_param[4, :] = bh_motor[\"x\"]\n",
    "# print('Somatomotor network parameters:' + str(np.round(bh_motor['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"ventral.h5\")\n",
    "bh_ventral = path.read_hdf5(h5_path)\n",
    "opt_param[6, :] = bh_ventral[\"x\"]\n",
    "# print('Ventral Attention network parameters:' + str(np.round(bh_ventral['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"visual.h5\")\n",
    "bh_visual = path.read_hdf5(h5_path)\n",
    "opt_param[2, :] = bh_visual[\"x\"]\n",
    "# print('Visual network parameters:' + str(np.round(bh_visual['x'],2)))\n",
    "\n",
    "# pile these parameters:\n",
    "parameters = pd.DataFrame(\n",
    "    data=opt_param, index=fc_dk_normalized.index, columns=[\"alpha\", \"wave_number\"]\n",
    ")\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for computing residuals & spatial correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linreg_scores(fnetworks, a, kk, fc_name, num_em, corr_type = \"spearman\", lap_type=\"complex\"):\n",
    "    # build the Brain object first:\n",
    "    brain = Brain.Brain()\n",
    "    brain.add_connectome(data_dir)\n",
    "    brain.reorder_connectome(brain.connectome, brain.distance_matrix)\n",
    "    brain.bi_symmetric_c()\n",
    "    brain.reduce_extreme_dir()\n",
    "\n",
    "    # decompose laplacian eigenmodes and pre-allocate array for correlation calculations\n",
    "    if lap_type is \"complex\":\n",
    "        #print('computing for complex laplacian')\n",
    "        brain.decompose_complex_laplacian(alpha=a, k=kk, vis=False)\n",
    "    elif lap_type is \"regular\":\n",
    "        #print('computing for regular laplacian')\n",
    "        brain.decompose_regular_laplacian(alpha=a)\n",
    "    elif lap_type is \"random\":\n",
    "        #print('computing for random laplacian')\n",
    "        brain.reducedConnectome = generate.exp_neg_dist_Cij(brain.distance_matrix)\n",
    "        brain.decompose_complex_laplacian(alpha=a, k=kk, vis=False)\n",
    "\n",
    "    # compute spatial correlation:\n",
    "    corrs = np.squeeze(np.zeros([brain.norm_eigenmodes.shape[1], 1]))\n",
    "    canon_network = np.nan_to_num(fnetworks.loc[fc_name].values)\n",
    "    for e in np.arange(0, len(corrs)):\n",
    "        if corr_type is \"spearman\":\n",
    "            prcorr = spearmanr(np.squeeze(canon_network), brain.norm_eigenmodes[:, e])[0]\n",
    "        elif corr_type is \"pearson\":\n",
    "            prcorr = pearsonr(np.squeeze(canon_network), brain.norm_eigenmodes[:, e])[0]\n",
    "        corrs[e] = prcorr\n",
    "\n",
    "    # sorting and pre-allocate for cumulative results\n",
    "    ntw_opt_corr = np.round(corrs, 3)\n",
    "    ordered_corr = np.argsort(-ntw_opt_corr)  # sort by correlation performance\n",
    "    cumulative_regr = np.zeros([num_em, 1])\n",
    "    cumulative_corr = np.zeros([num_em, 1])\n",
    "\n",
    "    # for each eigenmode, compute linear least square weights and combine:\n",
    "    for k in np.arange(0, num_em):\n",
    "        selected_eigs = brain.norm_eigenmodes[:, ordered_corr[0 : k + 1]]\n",
    "        coef, _, _, _ = lstsq(selected_eigs, canon_network, lapack_driver=\"gelsy\")\n",
    "\n",
    "        comb_corr = np.squeeze(np.matmul(selected_eigs, np.asarray(coef)))\n",
    "        dp = np.dot(selected_eigs, np.asarray(coef)) ** 2\n",
    "        residual = np.sum(canon_network - dp)\n",
    "\n",
    "        #cumulative_corr[k] = pearsonr(np.squeeze(canon_network), comb_corr)[0]\n",
    "        if corr_type is \"spearman\":\n",
    "            cumulative_corr[k] = spearmanr(np.squeeze(canon_network), comb_corr)[0]\n",
    "        if corr_type is \"pearson\":\n",
    "            cumulative_corr[k] = pearsonr(np.squeeze(canon_network), comb_corr)[0]\n",
    "        cumulative_regr[k] = residual\n",
    "    return np.squeeze(cumulative_regr), np.squeeze(cumulative_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above function for all functional networks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30  # number of eigenmodes\n",
    "regr_comp = np.zeros([K, 7])\n",
    "corr_comp = np.zeros([K, 7])\n",
    "\n",
    "for i in np.arange(0, len(fc_names)):\n",
    "    regr_comp[:, i], corr_comp[:, i] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=parameters.iloc[i, 0],\n",
    "        kk=parameters.iloc[i, 1],\n",
    "        fc_name=fc_dk_normalized.index[i],\n",
    "        num_em=K,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do the same for real laplacian:\n",
    "regr_reg = np.zeros([K, 7])\n",
    "corr_reg = np.zeros([K, 7])\n",
    "\n",
    "for i in np.arange(0, len(fc_names)):\n",
    "    regr_reg[:, i], corr_reg[:, i] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=parameters.iloc[i, 0],\n",
    "        kk=parameters.iloc[i, 1],\n",
    "        fc_name=fc_dk_normalized.index[i],\n",
    "        num_em=K,\n",
    "        lap_type=\"regular\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "## Random connectome based on distance:\n",
    "rng_runs = 1000\n",
    "np.random.seed(24)\n",
    "\n",
    "dft_rdnr = np.zeros([K, rng_runs])\n",
    "dft_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "limbic_rdnr = np.zeros([K, rng_runs])\n",
    "limbic_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "visual_rdnr = np.zeros([K, rng_runs])\n",
    "visual_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "front_rdnr = np.zeros([K, rng_runs])\n",
    "front_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "motor_rdnr = np.zeros([K, rng_runs])\n",
    "motor_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "ventral_rdnr = np.zeros([K, rng_runs])\n",
    "ventral_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "dorsal_rdnr = np.zeros([K, rng_runs])\n",
    "dorsal_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "for n in tqdm_notebook(np.arange(0, rng_runs), desc = 'random connectomes'):\n",
    "    limbic_rdnr[:, n], limbic_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_limbic[\"x\"][0],\n",
    "        kk=bh_limbic[\"x\"][1],\n",
    "        fc_name=\"Limbic\",\n",
    "        num_em=K,\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    dft_rdnr[:, n], dft_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_default[\"x\"][0],\n",
    "        kk=bh_default[\"x\"][1],\n",
    "        fc_name=\"Default\",\n",
    "        num_em=K,\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    visual_rdnr[:, n], visual_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_visual[\"x\"][0],\n",
    "        kk=bh_visual[\"x\"][1],\n",
    "        fc_name=\"Visual\",\n",
    "        num_em=K,\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    front_rdnr[:, n], front_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_front[\"x\"][0],\n",
    "        kk=bh_front[\"x\"][1],\n",
    "        fc_name=\"Frontoparietal\",\n",
    "        num_em=K,\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    motor_rdnr[:, n], motor_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_motor[\"x\"][0],\n",
    "        kk=bh_motor[\"x\"][1],\n",
    "        fc_name=\"Somatomotor\",\n",
    "        num_em=K,\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    dorsal_rdnr[:, n], dorsal_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_dorsal[\"x\"][0],\n",
    "        kk=bh_dorsal[\"x\"][1],\n",
    "        fc_name=\"Dorsal_Attention\",\n",
    "        num_em=K,\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    ventral_rdnr[:, n], ventral_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_ventral[\"x\"][0],\n",
    "        kk=bh_ventral[\"x\"][1],\n",
    "        fc_name=\"Ventral_Attention\",\n",
    "        num_em=K,\n",
    "        lap_type=\"random\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the intermediate results:\n",
    "np.savez('../data/distance_connectome_30eigs_rr.npz', limbic_regr = limbic_rdnr, limbic_corr = limbic_rdnc,\n",
    "        default_regr = dft_rdnr, default_corr = dft_rdnc,\n",
    "        visual_regr = visual_rdnr, visual_corr = visual_rdnc,\n",
    "        front_regr = front_rdnr, front_corr = front_rdnc,\n",
    "        motor_regr = motor_rdnr, motor_corr = motor_rdnc,\n",
    "        dorsal_regr = dorsal_rdnr, dorsal_corr = dorsal_rdnc,\n",
    "        ventral_regr = ventral_rdnr, ventral_corr = ventral_rdnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the npz file:\n",
    "cdist = np.load('../data/distance_connectome_30eigs_rr.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 95% confidence interval for null distribution error bars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def get_zscore(in_data):\n",
    "    sample_size = in_data.shape[1]\n",
    "    num_eig = in_data.shape[0]\n",
    "    confint = np.zeros([2,num_eig])\n",
    "    r2z_values = np.zeros([num_eig, sample_size])\n",
    "    \n",
    "    for eig in np.arange(0,num_eig):\n",
    "        z = np.arctanh(in_data[eig,:])\n",
    "        SDz = np.std(z)\n",
    "        cfstat = scipy.stats.norm.ppf(0.95)*SDz\n",
    "        confint[0,eig] = np.mean(in_data[eig,:]) - np.tanh(np.mean(in_data[eig,:])-cfstat) #lower\n",
    "        confint[1,eig] = np.tanh(np.mean(in_data[eig,:])+cfstat) - np.mean(in_data[eig,:]) #upper\n",
    "        r2z_values[eig,:] = z\n",
    "        #confint[0,eig] = np.tanh(np.mean(in_data[eig,:])-cfstat)-np.mean(in_data[eig,:]) #lower\n",
    "        #confint[1,eig] = np.tanh(np.mean(in_data[eig,:])+cfstat)-np.mean(in_data[eig,:]) #upper\n",
    "    upper_cfint = confint[1,:]\n",
    "    lower_cfint = confint[0,:]\n",
    "    return upper_cfint, lower_cfint, r2z_values\n",
    "\n",
    "def get_errorbar(in_data):\n",
    "    n = len(in_data)\n",
    "    xbar = np.mean(in_data)\n",
    "    s = np.std(in_data)\n",
    "    z = 1.96\n",
    "    \n",
    "    confint = np.zeros([2, n])\n",
    "    confint[0,:] = xbar - (xbar - (z * (s/np.sqrt(n))))\n",
    "    confint[1,:] = (xbar + (z * (s/np.sqrt(n)))) - xbar\n",
    "    return confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the performances for the 3 laplacians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "LW = 4\n",
    "cf = 0.95\n",
    "upper_cf = np.zeros([len(fc_names), K])\n",
    "lower_cf = np.zeros(upper_cf.shape)\n",
    "x = np.arange(1,K+1) # 1-K integers for x axis for number of eigenmodes\n",
    "rdn_spearman_mean = np.zeros([len(fc_names), K])\n",
    "\n",
    "c = 0\n",
    "for i, keys in enumerate(cdist.keys()):\n",
    "    if (i&1 == 1):\n",
    "        print(i, keys)\n",
    "        rdn_spearman_mean[c,:] = np.mean(cdist[keys], axis = 1)\n",
    "        upper_cf[c,:], lower_cf[c,:], _ = get_zscore(cdist[keys])\n",
    "        c += 1\n",
    "\n",
    "with plt.style.context('seaborn-paper'):\n",
    "    fit_fig, fit_ax = plt.subplots(1,7, figsize = (11,6.5), sharey = True)\n",
    "    for i, ax in enumerate(fit_ax):\n",
    "        ax.plot(x, corr_comp[0:K,i], color = 'orange', linewidth = LW)\n",
    "        ax.plot(x, corr_reg[0:K,i], color = 'blue', linewidth = LW)\n",
    "        ax.plot(x, rdn_spearman_mean[i,:], color = 'green', linewidth = LW)\n",
    "        ax.xaxis.set_major_locator(plt.MultipleLocator(10))\n",
    "        ax.title.set_text(fc_names[i])\n",
    "        ax.fill_between(x, rdn_spearman_mean[i,:] - lower_cf[i,:], rdn_spearman_mean[i,:] + upper_cf[i,:], \n",
    "                   color = 'darkslategray', alpha = 0.35)\n",
    "        \n",
    "    plt.legend(['Complex Laplacian', 'Real Laplacian', 'Random Laplacian'],\n",
    "              loc = 'center left', bbox_to_anchor = (1, 0.5))\n",
    "    \n",
    "    fit_fig.add_subplot(1,1,1, frameon = False)\n",
    "    plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
    "    plt.grid(False)\n",
    "    plt.ylabel(string.capwords(\"Spearman's Correlation\"), fontsize = 13)\n",
    "    plt.xlabel('Eigenmode Number', fontsize = 13)\n",
    "\n",
    "    plt.savefig('../figures/fig6/spearman.png', dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the same procedure but with Pearson correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2) into shape (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b1c54ed5e6ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mh5_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pearson_default.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbh_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mopt_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbh_default\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# print('Default network parameters:' + str(np.round(bh_default['x'],2)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2) into shape (3)"
     ]
    }
   ],
   "source": [
    "# load Pearson R optimized parameters:\n",
    "opt_param = np.zeros([len(fc_names), 3])\n",
    "\n",
    "## Load the optimized parameters first\n",
    "h5_path = os.path.join(data_dir, \"pearson_default.h5\")\n",
    "bh_default = path.read_hdf5(h5_path)\n",
    "opt_param[1, :] = bh_default[\"x\"]\n",
    "# print('Default network parameters:' + str(np.round(bh_default['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"pearson_dorsal.h5\")\n",
    "bh_dorsal = path.read_hdf5(h5_path)\n",
    "opt_param[5, :] = bh_dorsal[\"x\"]\n",
    "# print('Doral Attention network parameters:' + str(np.round(bh_dorsal['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"pearson_fronto.h5\")\n",
    "bh_front = path.read_hdf5(h5_path)\n",
    "opt_param[3, :] = bh_front[\"x\"]\n",
    "# print('Frontoparietal network parameters:' + str(np.round(bh_front['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"pearson_limbic.h5\")\n",
    "bh_limbic = path.read_hdf5(h5_path)\n",
    "opt_param[0, :] = bh_limbic[\"x\"]\n",
    "# print('Limbic network parameters:' + str(np.round(bh_limbic['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"pearson_motor.h5\")\n",
    "bh_motor = path.read_hdf5(h5_path)\n",
    "opt_param[4, :] = bh_motor[\"x\"]\n",
    "# print('Somatomotor network parameters:' + str(np.round(bh_motor['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"pearson_ventral.h5\")\n",
    "bh_ventral = path.read_hdf5(h5_path)\n",
    "opt_param[6, :] = bh_ventral[\"x\"]\n",
    "# print('Ventral Attention network parameters:' + str(np.round(bh_ventral['x'],2)))\n",
    "\n",
    "h5_path = os.path.join(data_dir, \"pearson_visual.h5\")\n",
    "bh_visual = path.read_hdf5(h5_path)\n",
    "opt_param[2, :] = bh_visual[\"x\"]\n",
    "# print('Visual network parameters:' + str(np.round(bh_visual['x'],2)))\n",
    "\n",
    "# pile these parameters:\n",
    "parameters = pd.DataFrame(\n",
    "    data=opt_param, index=fc_dk_normalized.index, columns=[\"alpha\", \"wave_number\"]\n",
    ")\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre-allocate space and define variables:\n",
    "K = 30  # number of eigenmodes\n",
    "regr_comp = np.zeros([K, 7])\n",
    "corr_comp = np.zeros([K, 7])\n",
    "## Do the same for regular laplacian:\n",
    "regr_reg = np.zeros([K, 7])\n",
    "corr_reg = np.zeros([K, 7])\n",
    "## Random connectome based on distance:\n",
    "rng_runs = 1000\n",
    "np.random.seed(24)\n",
    "\n",
    "dft_rdnr = np.zeros([K, rng_runs])\n",
    "dft_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "limbic_rdnr = np.zeros([K, rng_runs])\n",
    "limbic_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "visual_rdnr = np.zeros([K, rng_runs])\n",
    "visual_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "front_rdnr = np.zeros([K, rng_runs])\n",
    "front_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "motor_rdnr = np.zeros([K, rng_runs])\n",
    "motor_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "ventral_rdnr = np.zeros([K, rng_runs])\n",
    "ventral_rdnc = np.zeros([K, rng_runs])\n",
    "\n",
    "dorsal_rdnr = np.zeros([K, rng_runs])\n",
    "dorsal_rdnc = np.zeros([K, rng_runs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex Laplacian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(fc_names)):\n",
    "    regr_comp[:, i], corr_comp[:, i] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=parameters.iloc[i, 0],\n",
    "        kk=parameters.iloc[i, 1],\n",
    "        fc_name=fc_dk_normalized.index[i],\n",
    "        num_em=K,\n",
    "        corr_type = \"pearson\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Laplacian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(fc_names)):\n",
    "    regr_reg[:, i], corr_reg[:, i] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=parameters.iloc[i, 0],\n",
    "        kk=parameters.iloc[i, 1],\n",
    "        fc_name=fc_dk_normalized.index[i],\n",
    "        num_em=K,\n",
    "        corr_type = 'pearson',\n",
    "        lap_type=\"regular\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_dk_normalized.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random connectivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "for n in tqdm_notebook(np.arange(0, rng_runs), desc = 'random connectomes'):\n",
    "    limbic_rdnr[:, n], limbic_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_limbic[\"x\"][0],\n",
    "        kk=bh_limbic[\"x\"][1],\n",
    "        fc_name=\"Limbic\",\n",
    "        num_em=K,\n",
    "        corr_type = 'pearson',\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    dft_rdnr[:, n], dft_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_default[\"x\"][0],\n",
    "        kk=bh_default[\"x\"][1],\n",
    "        fc_name=\"Default\",\n",
    "        num_em=K,\n",
    "        corr_type = 'pearson',\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    visual_rdnr[:, n], visual_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_visual[\"x\"][0],\n",
    "        kk=bh_visual[\"x\"][1],\n",
    "        fc_name=\"Visual\",\n",
    "        num_em=K,\n",
    "        corr_type = 'pearson',\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    front_rdnr[:, n], front_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_front[\"x\"][0],\n",
    "        kk=bh_front[\"x\"][1],\n",
    "        fc_name=\"Frontoparietal\",\n",
    "        num_em=K,\n",
    "        corr_type = 'pearson',\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    motor_rdnr[:, n], motor_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_motor[\"x\"][0],\n",
    "        kk=bh_motor[\"x\"][1],\n",
    "        fc_name=\"Somatomotor\",\n",
    "        num_em=K,\n",
    "        corr_type = 'pearson',\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    dorsal_rdnr[:, n], dorsal_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_dorsal[\"x\"][0],\n",
    "        kk=bh_dorsal[\"x\"][1],\n",
    "        fc_name=\"Dorsal_Attention\",\n",
    "        num_em=K,\n",
    "        corr_type = 'pearson',\n",
    "        lap_type=\"random\",\n",
    "    )\n",
    "\n",
    "    ventral_rdnr[:, n], ventral_rdnc[:, n] = compute_linreg_scores(\n",
    "        fc_dk_normalized,\n",
    "        a=bh_ventral[\"x\"][0],\n",
    "        kk=bh_ventral[\"x\"][1],\n",
    "        fc_name=\"Ventral_Attention\",\n",
    "        num_em=K,\n",
    "        corr_type = 'pearson',\n",
    "        lap_type=\"random\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the intermediate results:\n",
    "np.savez('../data/distance_connectome_30eigs_pearson_rr.npz', limbic_regr = limbic_rdnr, limbic_corr = limbic_rdnc,\n",
    "        default_regr = dft_rdnr, default_corr = dft_rdnc,\n",
    "        visual_regr = visual_rdnr, visual_corr = visual_rdnc,\n",
    "        front_regr = front_rdnr, front_corr = front_rdnc,\n",
    "        motor_regr = motor_rdnr, motor_corr = motor_rdnc,\n",
    "        dorsal_regr = dorsal_rdnr, dorsal_corr = dorsal_rdnc,\n",
    "        ventral_regr = ventral_rdnr, ventral_corr = ventral_rdnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load intermediate results:\n",
    "cdist = np.load('../data/distance_connectome_30eigs_pearson_rr.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "LW = 4\n",
    "cf = 0.95\n",
    "upper_cf = np.zeros([len(fc_names), K])\n",
    "lower_cf = np.zeros(upper_cf.shape)\n",
    "x = np.arange(1,K+1) # 1-K integers for x axis for number of eigenmodes\n",
    "rdn_pearson_mean = np.zeros([len(fc_names), K])\n",
    "\n",
    "c = 0\n",
    "for i, keys in enumerate(cdist.keys()):\n",
    "    if (i&1 == 1):\n",
    "        print(i, keys)\n",
    "        rdn_pearson_mean[c,:] = np.mean(cdist[keys], axis = 1)\n",
    "        upper_cf[c,:], lower_cf[c,:], _ = get_zscore(cdist[keys])\n",
    "        c += 1\n",
    "\n",
    "with plt.style.context('ggplot'):\n",
    "    fit_fig, fit_ax = plt.subplots(1,7, figsize = (11,6.5), sharey = True)\n",
    "    for i, ax in enumerate(fit_ax):\n",
    "        ax.plot(x, corr_comp[0:K,i], color = 'orange', linewidth = LW)\n",
    "        ax.plot(x, corr_reg[0:K,i], color = 'blue', linewidth = LW)\n",
    "        ax.plot(x, rdn_pearson_mean[i,:], color = 'green', linewidth = LW)\n",
    "        ax.xaxis.set_major_locator(plt.MultipleLocator(10))\n",
    "        ax.title.set_text(fc_names[i])\n",
    "        ax.fill_between(x, rdn_pearson_mean[i,:] - lower_cf[i,:], rdn_pearson_mean[i,:] + upper_cf[i,:], \n",
    "                   color = 'darkslategray', alpha = 0.35)\n",
    "        \n",
    "    plt.legend(['Complex Laplacian', 'Real Laplacian', 'Random Laplacian'],\n",
    "              loc = 'center left', bbox_to_anchor = (1, 0.5))\n",
    "    \n",
    "    fit_fig.add_subplot(1,1,1, frameon = False)\n",
    "    plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
    "    plt.grid(False)\n",
    "    plt.ylabel(string.capwords(\"Pearson's Correlation\"), fontsize = 13)\n",
    "    plt.xlabel('Eigenmode Number', fontsize = 13)\n",
    "\n",
    "    #plt.savefig('../figures/fig6/pearson.png', dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Spectral)",
   "language": "python",
   "name": "spectral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
